{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/shakespeare.txt', 'r', encoding='utf8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                     1\n",
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose might never die,\n",
      "  But as the riper should by time decease,\n",
      "  His tender heir might bear his memory:\n",
      "  But thou contracted to thine own bright eyes,\n",
      "  Feed'st thy light's flame with self-substantial fuel,\n",
      "  Making a famine where abundance lies,\n",
      "  Thy self thy foe, to thy sweet self too cruel:\n",
      "  Thou that art now the world's fresh ornament,\n",
      "  And only herald to the gaudy spring,\n",
      "  Within thine own bud buriest thy content,\n",
      "  And tender churl mak'st waste in niggarding:\n",
      "    Pity the world, or else this glutton be,\n",
      "    To eat the world's due, by the grave and thee.\n",
      "\n",
      "\n",
      "                     2\n",
      "  When forty winters shall besiege thy brow,\n",
      "  And dig deep trenches in thy beauty's field,\n",
      "  Thy youth's proud livery so gazed on now,\n",
      "  Will be a tattered weed of small worth held:  \n",
      "  Then being asked, where all thy beauty lies,\n",
      "  Where all the treasure of thy lusty days;\n",
      "  To say within thine own deep su\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5445609"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_characters = set(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'L')\n",
      "(1, '&')\n",
      "(2, 'o')\n",
      "(3, 'D')\n",
      "(4, 'x')\n",
      "(5, 'R')\n",
      "(6, '<')\n",
      "(7, 'T')\n",
      "(8, 'H')\n",
      "(9, 'i')\n",
      "(10, '4')\n",
      "(11, 'm')\n",
      "(12, 'W')\n",
      "(13, '2')\n",
      "(14, '(')\n",
      "(15, '|')\n",
      "(16, 'g')\n",
      "(17, 'N')\n",
      "(18, 'I')\n",
      "(19, 'f')\n",
      "(20, 'r')\n",
      "(21, '\"')\n",
      "(22, 's')\n",
      "(23, '8')\n",
      "(24, '?')\n",
      "(25, '[')\n",
      "(26, 'a')\n",
      "(27, 'z')\n",
      "(28, ':')\n",
      "(29, 'Z')\n",
      "(30, 't')\n",
      "(31, '6')\n",
      "(32, 'u')\n",
      "(33, 'e')\n",
      "(34, \"'\")\n",
      "(35, '0')\n",
      "(36, 'S')\n",
      "(37, 'Q')\n",
      "(38, 'j')\n",
      "(39, 'O')\n",
      "(40, 'M')\n",
      "(41, 'w')\n",
      "(42, '>')\n",
      "(43, 'y')\n",
      "(44, 'V')\n",
      "(45, '}')\n",
      "(46, 'd')\n",
      "(47, 'k')\n",
      "(48, 'q')\n",
      "(49, 'F')\n",
      "(50, ')')\n",
      "(51, 'C')\n",
      "(52, '.')\n",
      "(53, 'J')\n",
      "(54, 'b')\n",
      "(55, 'p')\n",
      "(56, 'A')\n",
      "(57, 'Y')\n",
      "(58, 'n')\n",
      "(59, '3')\n",
      "(60, '-')\n",
      "(61, 'l')\n",
      "(62, '`')\n",
      "(63, '!')\n",
      "(64, 'X')\n",
      "(65, '7')\n",
      "(66, 'E')\n",
      "(67, ';')\n",
      "(68, '\\n')\n",
      "(69, 'h')\n",
      "(70, ' ')\n",
      "(71, ']')\n",
      "(72, 'U')\n",
      "(73, '9')\n",
      "(74, ',')\n",
      "(75, 'K')\n",
      "(76, '_')\n",
      "(77, '5')\n",
      "(78, '1')\n",
      "(79, 'B')\n",
      "(80, 'v')\n",
      "(81, 'P')\n",
      "(82, 'G')\n",
      "(83, 'c')\n"
     ]
    }
   ],
   "source": [
    "for pair in enumerate(all_characters):\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decoder\n",
    "# num --> letter\n",
    "\n",
    "decoder = dict(enumerate(all_characters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder\n",
    "# letter --> num\n",
    "\n",
    "encoder = {char: ind for ind,char in decoder.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'L': 0,\n",
       " '&': 1,\n",
       " 'o': 2,\n",
       " 'D': 3,\n",
       " 'x': 4,\n",
       " 'R': 5,\n",
       " '<': 6,\n",
       " 'T': 7,\n",
       " 'H': 8,\n",
       " 'i': 9,\n",
       " '4': 10,\n",
       " 'm': 11,\n",
       " 'W': 12,\n",
       " '2': 13,\n",
       " '(': 14,\n",
       " '|': 15,\n",
       " 'g': 16,\n",
       " 'N': 17,\n",
       " 'I': 18,\n",
       " 'f': 19,\n",
       " 'r': 20,\n",
       " '\"': 21,\n",
       " 's': 22,\n",
       " '8': 23,\n",
       " '?': 24,\n",
       " '[': 25,\n",
       " 'a': 26,\n",
       " 'z': 27,\n",
       " ':': 28,\n",
       " 'Z': 29,\n",
       " 't': 30,\n",
       " '6': 31,\n",
       " 'u': 32,\n",
       " 'e': 33,\n",
       " \"'\": 34,\n",
       " '0': 35,\n",
       " 'S': 36,\n",
       " 'Q': 37,\n",
       " 'j': 38,\n",
       " 'O': 39,\n",
       " 'M': 40,\n",
       " 'w': 41,\n",
       " '>': 42,\n",
       " 'y': 43,\n",
       " 'V': 44,\n",
       " '}': 45,\n",
       " 'd': 46,\n",
       " 'k': 47,\n",
       " 'q': 48,\n",
       " 'F': 49,\n",
       " ')': 50,\n",
       " 'C': 51,\n",
       " '.': 52,\n",
       " 'J': 53,\n",
       " 'b': 54,\n",
       " 'p': 55,\n",
       " 'A': 56,\n",
       " 'Y': 57,\n",
       " 'n': 58,\n",
       " '3': 59,\n",
       " '-': 60,\n",
       " 'l': 61,\n",
       " '`': 62,\n",
       " '!': 63,\n",
       " 'X': 64,\n",
       " '7': 65,\n",
       " 'E': 66,\n",
       " ';': 67,\n",
       " '\\n': 68,\n",
       " 'h': 69,\n",
       " ' ': 70,\n",
       " ']': 71,\n",
       " 'U': 72,\n",
       " '9': 73,\n",
       " ',': 74,\n",
       " 'K': 75,\n",
       " '_': 76,\n",
       " '5': 77,\n",
       " '1': 78,\n",
       " 'B': 79,\n",
       " 'v': 80,\n",
       " 'P': 81,\n",
       " 'G': 82,\n",
       " 'c': 83}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_text = np.array([encoder[char] for char in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([68, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
       "       70, 70, 70, 70, 70, 78, 68, 70, 70, 49, 20,  2, 11, 70, 19, 26,  9,\n",
       "       20, 33, 22, 30, 70, 83, 20, 33, 26, 30, 32, 20, 33, 22, 70, 41, 33,\n",
       "       70, 46, 33, 22,  9, 20, 33, 70,  9, 58, 83, 20, 33, 26, 22, 33, 74,\n",
       "       68, 70, 70,  7, 69, 26, 30, 70, 30, 69, 33, 20, 33, 54, 43, 70, 54,\n",
       "       33, 26, 32, 30, 43, 34, 22, 70, 20,  2, 22, 33, 70, 11,  9, 16, 69,\n",
       "       30, 70, 58, 33, 80, 33, 20, 70, 46,  9, 33, 74, 68, 70, 70, 79, 32,\n",
       "       30, 70, 26, 22, 70, 30, 69, 33, 70, 20,  9, 55, 33, 20, 70, 22, 69,\n",
       "        2, 32, 61, 46, 70, 54, 43, 70, 30,  9, 11, 33, 70, 46, 33, 83, 33,\n",
       "       26, 22, 33, 74, 68, 70, 70,  8,  9, 22, 70, 30, 33, 58, 46, 33, 20,\n",
       "       70, 69, 33,  9, 20, 70, 11,  9, 16, 69, 30, 70, 54, 33, 26, 20, 70,\n",
       "       69,  9, 22, 70, 11, 33, 11,  2, 20, 43, 28, 68, 70, 70, 79, 32, 30,\n",
       "       70, 30, 69,  2, 32, 70, 83,  2, 58, 30, 20, 26, 83, 30, 33, 46, 70,\n",
       "       30,  2, 70, 30, 69,  9, 58, 33, 70,  2, 41, 58, 70, 54, 20,  9, 16,\n",
       "       69, 30, 70, 33, 43, 33, 22, 74, 68, 70, 70, 49, 33, 33, 46, 34, 22,\n",
       "       30, 70, 30, 69, 43, 70, 61,  9, 16, 69, 30, 34, 22, 70, 19, 61, 26,\n",
       "       11, 33, 70, 41,  9, 30, 69, 70, 22, 33, 61, 19, 60, 22, 32, 54, 22,\n",
       "       30, 26, 58, 30,  9, 26, 61, 70, 19, 32, 33, 61, 74, 68, 70, 70, 40,\n",
       "       26, 47,  9, 58, 16, 70, 26, 70, 19, 26, 11,  9, 58, 33, 70, 41, 69,\n",
       "       33, 20, 33, 70, 26, 54, 32, 58, 46, 26, 58, 83, 33, 70, 61,  9, 33,\n",
       "       22, 74, 68, 70, 70,  7, 69, 43, 70, 22, 33, 61, 19, 70, 30, 69, 43,\n",
       "       70, 19,  2, 33, 74, 70, 30,  2, 70, 30, 69, 43, 70, 22, 41, 33, 33,\n",
       "       30, 70, 22, 33, 61, 19, 70, 30,  2,  2, 70, 83, 20, 32, 33, 61, 28,\n",
       "       68, 70, 70,  7, 69,  2, 32, 70, 30])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text[:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder[70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoder(encoded_text, num_uni_chars):\n",
    "    #encoded_text --> batch of encoded text\n",
    "    #num of unique characters --> len(set(text))\n",
    "    \n",
    "    one_hot = np.zeros((encoded_text.size, num_uni_chars))\n",
    "    \n",
    "    one_hot = one_hot.astype(np.float32)\n",
    "    \n",
    "    one_hot[np.arange(one_hot.shape[0]), encoded_text.flatten()] = 1.0\n",
    "    \n",
    "    one_hot = one_hot.reshape((*encoded_text.shape, num_uni_chars))\n",
    "    \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([1,2,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoder(arr, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What batches I want now?\n",
    "\n",
    "X = [H,e,l,l,o]\n",
    "Y [e,l,l,o, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text = np.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [2, 3],\n",
       "       [4, 5],\n",
       "       [6, 7],\n",
       "       [8, 9]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_text.reshape((5,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batches(encoded_text, samp_per_batch=10, seq_len=50):\n",
    "    # X : encoded text of len seq_len\n",
    "    # Y : encoded text shifted by 1\n",
    "    \n",
    "    char_per_batch = samp_per_batch * seq_len\n",
    "    \n",
    "    num_batches_available = int(len(encoded_text)/char_per_batch)\n",
    "    \n",
    "    encoded_text = encoded_text[:num_batches_available*char_per_batch]\n",
    "    \n",
    "    encoded_text = encoded_text.reshape((samp_per_batch,-1))\n",
    "    \n",
    "    for n in range(0, encoded_text.shape[1],seq_len):\n",
    "        x = encoded_text[:, n:n+seq_len]\n",
    "        \n",
    "        y = np.zeros_like(x)\n",
    "        \n",
    "        try:\n",
    "            y[:, :-1] = x[:,1:]\n",
    "            y[:,-1] = encoded_text[:,n+seq_len]\n",
    "            \n",
    "        except:\n",
    "            y[:,:-1] = x[:,1:]\n",
    "            y[:,:-1] = encoded_text[:,0]\n",
    "            \n",
    "        yield x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = encoded_text[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([68, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
       "       70, 70, 70])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_generator = generate_batches(sample_text, samp_per_batch=2, seq_len=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(batch_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[68, 70, 70, 70, 70],\n",
       "       [70, 70, 70, 70, 70]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[70, 70, 70, 70, 70],\n",
       "       [70, 70, 70, 70, 70]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharModel(nn.Module):\n",
    "    def __init__(self, all_chars, num_hidden=256, num_layers=4, drop_prob=0.5, use_gpu=True):\n",
    "        super().__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "        self.num_layers = num_layers\n",
    "        self.num_hidden = num_hidden\n",
    "        self.use_gpu = use_gpu\n",
    "        \n",
    "        self.all_chars = all_chars\n",
    "        self.decoder = dict(enumerate(all_chars))\n",
    "        self.encoder = {char: ind for ind,char in decoder.items()}\n",
    "        \n",
    "        self.lstm = nn.LSTM(len(self.all_chars), num_hidden, num_layers, dropout=drop_prob, batch_first=True)\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        self.fcl = nn.Linear(num_hidden, len(self.all_chars))\n",
    "        \n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        lstm_output, hidden = self.lstm(x, hidden)\n",
    "        \n",
    "        drop_output = self.dropout(lstm_output)\n",
    "        drop_output = drop_output.contiguous().view(-1, self.num_hidden)\n",
    "        \n",
    "        final_output = self.fcl(drop_output)\n",
    "        \n",
    "        return final_output, hidden\n",
    "    \n",
    "    \n",
    "    def hidden_state(self, batch_size):\n",
    "        if self.use_gpu:\n",
    "            hidden = (torch.zeros(self.num_layers, batch_size, self.num_hidden).cuda(),\n",
    "                      torch.zeros(self.num_layers, batch_size, self.num_hidden).cuda())\n",
    "            \n",
    "        else:\n",
    "            hidden = (torch.zeros(self.num_layers, batch_size, self.num_hidden),\n",
    "                      torch.zeros(self.num_layers, batch_size, self.num_hidden))\n",
    "            \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CharModel(all_chars=all_characters,\n",
    "                 num_hidden=256,\n",
    "                 num_layers=4,\n",
    "                 drop_prob=0.5,\n",
    "                 use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86016\n",
      "262144\n",
      "1024\n",
      "1024\n",
      "262144\n",
      "262144\n",
      "1024\n",
      "1024\n",
      "262144\n",
      "262144\n",
      "1024\n",
      "1024\n",
      "262144\n",
      "262144\n",
      "1024\n",
      "1024\n",
      "21504\n",
      "84\n"
     ]
    }
   ],
   "source": [
    "total_params = []\n",
    "\n",
    "for param in model.parameters():\n",
    "    print(param.numel())\n",
    "    total_params.append(int(param.numel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1950804"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_percent = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ind = int(len(encoded_text)*train_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = encoded_text[:train_ind]\n",
    "valid_data = encoded_text[train_ind:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "544560"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4901049"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_percent = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5445609"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ind = int(len(encoded_text) * train_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = encoded_text[:train_ind]\n",
    "valid_data = encoded_text[train_ind:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4901048"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "544561"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
